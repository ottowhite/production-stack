servingEngineSpec:
  strategy:
    type: Recreate
  runtimeClassName: ""
  modelSpec:
  - name: "llama3-8b"
    repository: "vllm/vllm-openai"
    tag: "latest"
    modelURL: "meta-llama/Meta-Llama-3-8B-Instruct"
    replicaCount: 2
    requestCPU: 6
    requestMemory: "16Gi"
#     requestGPU: 0.5
    requestGPU: 1

    vllmConfig:
      maxModelLen: 1024
      gpuMemoryUtilization: 0.4
      extraArgs: ["--disable-log-requests"]

    envFromSecret:
      name: "dotenv-secret"
